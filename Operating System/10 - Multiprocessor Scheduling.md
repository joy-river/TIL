### Cache

---

- 캐시는 작지만 매우 빠른 속도를 가지는 cpu 내장 메모리이다.

  - 메인 메모리와 비교했을 때 아득히 빠른 속도를 가지고 있다.

- 자주 접근하는(popular) 데이터의 복사본을 저장하고 있다.

  - 메인 메모리는 모든 데이터를 가지고 있다.

  - 메인 메모리의 데이터를 캐시로 불러오고, 캐시는 그 정보를 저장한다.

    - 똑같은 데이터를 요구할때, 메인 메모리에 접근하지 않고 캐시에서 들고 올 수 있다.

  - 캐시의 속도가 훨씬 빠르므로, 프로그램의 전체적인 성능을 향상시킬 수 있다.

- 프로그램에는 두 가지 지역성이 있다.

  - 시간적 지역성(temporal locality)

    - 시간적 지역성은 한 데이터가 가까운 시일 내로 다시 접근될 확률이 높음을 의미한다.

  - 공간적 지역성(spatial locality)

    - 공간적 지역성은 한 데이터가 사용되면, 그 근처의 데이터도 접근될 확률이 높음을 의미한다.

  - 이 두 가지 지역성을 캐시를 통해 활용할 수 있다.

- Cache Coherence

  - 캐시 일관성이란, 시스템에 여러 cpu core가 있을 때 각 코어마다 캐시를 가지는 경우에 발생하는 문제이다.

    - cpu1에서 메인 메모리의 D를 가져오고,

    - cpu0에서 똑같은 주소의 D를 가져온 후에 연산을 진행, D'으로 만들고 캐시에 저장해 놓았다.

      - Delayed write에 의해 메인 메모리에 즉각적으로 접근하지 않는다.

      - write back은 어느정도 시간이 지난 후에 수행된다.

    - cpu1은 D를, cpu0는 D'를, 메인 메모리는 D를 그대로 가지고있다.

    - cpu1가 다시 D'에 해당하는 데이터를 불러오고 싶다.

      - 근데 옛 버전의 D를 가져오게 된다.

      - 이를 캐시 일관성 문제라고 한다.

  - 이를 해결하는 방법 중 하나가 하드웨어를 통한 Bus snooping이다.

    - 각 캐시가 메모리 버스를 관측한다.

    - 버스에서 메모리가 업데이트 되는것을 관측하면, 자기가 가지고있던 복제본을 무효처리하거나 업데이트 한다.

  - 우리는 동기화에 대해 이미 다룬적이 있다.

    - 상호배제를 통해 캐시 일관성 문제를 해결할 수 있다.

- Cache Affinity

  - 캐시 선호도란 가능하다면 동일한 cpu에서 프로세스를 실행하는 것이다.

    - 프로세스는 여러 cpu 중 하나에서 실행될 수 있고, 스케줄러가 어느 cpu에서 프로세스를 실행할지 결정한다.

    - 실행된 프로세스는 그 cpu 코어의 캐시에 자신의 상태를 저장해놓는다.

      - 다른 cpu에서 프로세스를 실행하려고 하면, 또 다시 프로세스의 상태를 불러와야한다. = 지연이 발생한다.

    - 따라서 이미 실행했던 적이 있는 cpu에서 다시 프로세스를 실행하는 편이 낫다!

  - 따라서 스케줄러는 캐시 선호도를 고려해야한다.

### Multiprocessor Scheduling

---

- SQMS(Single Queue Multiprocessor Scheduling)

  - 단 하나의 큐를 가지고 구현한 스케줄러.

  - 큐에 모든 작업을 때려넣고, cpu마다 큐에서 작업을 가져간다.

    - 작업의 time slice가 끝나면 다시 큐에 들어간다.

  - 문제가 겁나게 많다!

    - 동일한 큐에 여러 코어가 접근하므로, 동기화 문제를 방지하기 위해 Mutex(동기화 매커니즘)이 필수적으로 들어가야한다.

      - 이는 scalability = 확장성을 없애고, 지연을 발생시킨다.

    - 캐시 선호도? 개무시된다.

  - 캐시 선호도를 고려해서 스케줄링하고 싶다.

    - A가 cpu0에서 실행되면, A는 cpu0에 대한 선호를 가진다.

    - 이런 선호를 유지하면서 스케줄링을 하고 싶지만, 매우 복잡하다.

- MQMS(Multi-Queue MultiProcessor Scheduling)

  - 여러 큐를 가지고 각 큐마다 특정한 스케줄링 규칙을 따르게 한다.

    - 각 큐는 각 cpu 코어에 할당되어있다.

  - 어떤 작업이 시스템이 들어오면, 그 작업은 무조건 하나의 큐에만 머무르게 된다.

    - 공유 자원이 생기지 않는다.

  - information sharing과 synchronization 문제를 해결할 수 있다.

  - 큐 내부에서 RR을 사용해 스케줄링 할 수 있다.

    - cpu0는 Q0에서 A, C 작업만 스케줄링 받는다.

    - cpu1은 Q1에서 B, D 작업만 스케줄링 받는다.

  - MQMS는 확장성과 캐시 선호도를 둘 다 얻을 수 있다.

    - Synchronization Primitives를 사용하지 않으니까.

  - 하지만 완벽한건 아니다!

  - Load Imbalance(부하 불균형)

    - 특정 큐의 작업이 적을 경우 특정 프로세스가 cpu를 독점한다.

    - 특정 큐에 아무 작업도 없을 경우 다른 cpu는 열심히 일 하는데, 특정 cpu는 자빠져 잔다.

  - 이를 해결하기 위해 migration이 필요하다.

    - 다른 큐에 있는 작업을 특정 큐로 옮긴다.

    - 비어있는 cpu에는 아무 작업이나 옮겨도 문제가 없다.

    - 그런데 프로세스 숫자가 작을 뿐인 cpu는 어떡하면 좋을까?

      - 작업 1개와 2개로 나뉘어져 있을 경우

      - 1개가 작업을 가져가면 2개가 되어버리니까 서로 작업을 계속 바꾸고, 바꾸고... 지연이 생기게 된다.

  - migration을 구현하는 방법은 Work Stealing이 있다.

    - 큐 사이에서 작업을 옮긴다.

      - Source queue = 적은 양의 작업을 가진 큐가 선택된다.

      - 이 소스 큐는 다른 바쁜 큐(=target queue)를 슬쩍 훔쳐본다.

      - 타겟이 된 큐가 소스 큐보다 작업이 많다면, 소스 큐는 작업을 한개 이상 훔쳐온다.

    - 여기서도 문제가 있다.

- 리눅스가 사용하는 스케줄링 알고리즘을 또 살펴보자.

  - CFS는 이미 살펴봤다.

    - Deterministic proportional-share approach

    - Multiple Queues

  - O(1) 알고리즘

    - 멀티 코어를 위해 디자인되었다.

    - Multiple Queues

    - CFS와 다르게 Priority based algorithm

      - 시간에 따라 프로세스의 우선순위를 바꾼다.

    - Interactivity = response time을 목적으로 하는 알고리즘

  - BFS(BF Scheduler)

    - Single Queue Approach

    - Proportional-share

    - Based on EEVDF(Earliest Eligible Virtual Deadline First) algorithm
